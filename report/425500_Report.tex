\documentclass[12pt,oneside]{book} % for one-sided printing

\usepackage{blindtext}% Just used so we can generate some example text
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage[export]{adjustbox}
\usepackage{lipsum}
\usepackage{booktabs}  % For better quality tables
\usepackage{tabularx}  % for the X column type
\usepackage{listings}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{xfrac}
\usepackage{indentfirst}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% Place style file after other packages.
\usepackage{cranfieldthesis}
\usepackage{lscape} % for landscape pages
\usepackage{float}
\usepackage[toc,title,page]{appendix}

% Couleurs personnalisées
\definecolor{backcolour}{rgb}{0.96, 0.96, 0.96} % Fond très clair
\definecolor{codegray}{rgb}{0.47, 0.47, 0.47}   % Commentaires et numéros de ligne
\definecolor{codegreen}{rgb}{0.25, 0.50, 0.35}  % Commentaires
\definecolor{codeblue}{rgb}{0.26, 0.44, 0.58}   % Mots-clés
\definecolor{codepurple}{rgb}{0.50, 0, 0.50}    % Identificateurs
\definecolor{codeteal}{rgb}{0, 0.5, 0.5}        % Chaînes de caractères
\definecolor{terminalback}{rgb}{0.05, 0.05, 0.05} % Fond très sombre pour le terminal
\definecolor{terminaltext}{rgb}{0.7, 0.7, 0.7}    % Texte clair pour le terminal
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\definecolor{terminalbgcolor}{HTML}{330033}
\definecolor{terminalrulecolor}{HTML}{000099}

\lstdefinestyle{pythonstyle}{
    language=Python,
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{codeblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codeteal},
    identifierstyle=\color{codepurple},
    basicstyle=\ttfamily\scriptsize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    frame=single,
    rulecolor=\color{codegray},
    framexleftmargin=15pt,
    framextopmargin=5pt,
    framexbottommargin=5pt,
    framexrightmargin=15pt,
}

\lstdefinestyle{bashstyle}{
    language=bash,
    backgroundcolor=\color{backcolour},
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    identifierstyle=\color{codepurple},
    commentstyle=\color{codegreen},
    morecomment=[l]{\#},   % Define comment style
    frame=single,          % adds a frame around the code
    rulecolor=\color{gray},% if not set, the frame-color may be changed on line-breaks
    breakatwhitespace=false,
    breaklines=true,       % sets automatic line breaking
    captionpos=b,          % sets the caption-position to bottom
    keepspaces=true,       % keeps spaces in text
    showspaces=false,      % show spaces everywhere adding particular underscores
    showstringspaces=false % underline spaces within strings only
}

\lstdefinestyle{ymlstyle}{
    language=Python,
    backgroundcolor=\color{backcolour},
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    identifierstyle=\color{codepurple},
    commentstyle=\color{codegreen},
    morecomment=[l]{\#},   % Define comment style
    frame=single,          % adds a frame around the code
    rulecolor=\color{gray},% if not set, the frame-color may be changed on line-breaks
    breakatwhitespace=false,
    breaklines=true,       % sets automatic line breaking
    captionpos=b,          % sets the caption-position to bottom
    keepspaces=true,       % keeps spaces in text
    showspaces=false,      % show spaces everywhere adding particular underscores
    showstringspaces=false, % underline spaces within strings only
    literate=% Special handling for dot notations
        {http.response_time.p99}{{\textcolor{blue}{http.response\_time.p99}}}{18}
        {http.response_time.p95}{{\textcolor{blue}{http.response\_time.p95}}}{18}
        {metrics-by-endpoint}{{\textcolor{blue}{metrics-by-endpoint}}}{16},
    morekeywords={config, flow, target, phases, plugins, scenarios, loop, get, url, count, ensure, apdex, threshold, thresholds, duration, arrivalRate, name, pause, metrics -by-endpoint}, % Additional YAML-specific keywords
}

\lstdefinestyle{cstyle}{
    language=C++,
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue},
    backgroundcolor=\color{backcolour},
    stringstyle=\color{red},
    commentstyle=\color{codegreen},
    morecomment=[l][\color{magenta}]{\#},
    breaklines=true,
    numbers=left,
    numberstyle=\tiny\color{gray},
    showstringspaces=false,
    tabsize=2,
    frame=single
}

% Title Page Set Up
\title{High Performance Technical Computing Assignment}
\author{Alexis Balayre}
\date{5\textsuperscript{th} February 2024}
\school{\SATM}
\degree{MSc}
\course{Computational Software of Techniques Engineering}
\academicyear{2023 - 2024}

% Supervisors
\supervisor{Dr Irene Moulitsas}

% Copyright
\copyrightyear{2024}

% References
\usepackage[numbers]{natbib} % for nice referencing
\makeatletter % Reference list option change to number and period
\renewcommand\@biblabel[1]{#1.} % from [1] to 1
\makeatother %
\setcitestyle{round} % use round citations

\begin{document}

\frontmatter

% Form Title Pages
\maketitle

% Abstract and Keywords
\begin{abstract}
    Replace with your abstract text of not more than 300 words.
\end{abstract}

% Acknowledgements
\chapter{Acknowledgements}
The author would like to thank \dots

% Use single spacing for Table of Contents, List of Figures, etc
{
    \clearpage
    \singlespacing
    % Table of Contents
    {
        \tableofcontents
    }
    \clearpage

    % List of Figures
    \listoffigures

    % List of Tables
    \listoftables
}

%% Main Matter
\mainmatter
\pagestyle{fancy}
\fancyhead[L]{\nouppercase{\leftmark}}
\fancyhead[R]{\nouppercase{\rightmark}}

\chapter{Introduction}

\chapter{Methodology}
\section{Sequential Algorithm}

The algorithm for multiplying a sparse matrix by a dense vector can be
efficiently implemented using the Compressed Sparse Row (CSR) format. The CSR
format represents a sparse matrix using three arrays: \texttt{values},
\texttt{col\_indices}, and \texttt{row\_pointers}. Given a sparse matrix \( M
\) in CSR format and a dense vector \( v \), the product \( M \times v \) is
computed as follows:

\begin{algorithm}[H]
    \caption{Sequential algorithm}
    \begin{algorithmic}
        \Require $M$ is an $m \times n$ sparse matrix
        \Require $v$ is an $n \times k$ dense vector
        \Ensure  $Result$ is an $m \times k$ matrix
        \State $Result \gets$ zero matrix of size $m \times k$
        \For{$i \gets 0$ \textbf{to} $m-1$}
        \For{each non-zero element $(j, \text{value})$ in row $i$ of $M$}
        \For{$l \gets 0$ \textbf{to} $k-1$}
        \State $Result[i][l] \gets Result[i][l] + (\text{value} \times v[j][l])$
        \EndFor
        \EndFor
        \EndFor
        \State \Return $Result$
    \end{algorithmic}
\end{algorithm}

\subsection{Complexity Analysis}

The complexity analysis of the algorithm for multiplying a sparse matrix by a
dense vector focuses on two main aspects: temporal complexity and spatial
complexity.

\subsubsection{Temporal Complexity}

The temporal complexity of the algorithm depends on how the sparse matrix is
stored and the number of non-zero elements in the matrix.

\begin{itemize}
    \item \textbf{Traversing Rows:} The algorithm traverses each row of the matrix. If the matrix has \( m \) rows, this step has a complexity of \( O(m) \).
    \item \textbf{Traversing Non-Zero Elements:} Inside each row, the algorithm traverses the non-zero elements. If the total number of non-zero elements in the matrix is \( n_{nz} \), the traversal of all these elements has a complexity of \( O(n_{nz}) \).
\end{itemize}

The total temporal complexity is therefore \( O(m + n_{nz}) \). However, in
practice, this complexity is often considered as \( O(n_{nz}) \), as the number
of non-zero elements is usually the dominating factor, especially in very
sparse matrices.

\subsubsection{Spatial Complexity}

The spatial complexity is related to the amount of memory required by the
algorithm.

\begin{itemize}
    \item \textbf{Storing the Sparse Matrix:} The way the sparse matrix is stored affects the spatial complexity. Generally, storage formats like CSR or COO allow storing a sparse matrix with a complexity of \( O(n_{nz}) \), where \( n_{nz} \) is the number of non-zero elements.
    \item \textbf{Dense Vector:} The dense vector has a spatial complexity of \( O(n) \), where \( n \) is the size of the vector.
    \item \textbf{Result Vector:} The result vector also has a size of \( O(m) \), where \( m \) is the number of rows in the matrix.
\end{itemize}

The total spatial complexity is therefore \( O(n_{nz} + m + n) \), but in
practice, the focus is mainly on the \( O(n_{nz}) \) term as it is generally
the most significant.

\newpage
\subsection{Example}

Dans le format CSR, la matrice est représentée par trois vecteurs :
\texttt{values}, \texttt{rows}, et \texttt{cols}. Pour notre exemple, ces
vecteurs sont définis comme suit:
\begin{itemize}
    \item \texttt{values} = \{1, 2, 3, 4\}
    \item \texttt{rows} = \{0, 2, 3, 3, 4\}
    \item \texttt{cols} = \{0, 2, 1, 3\}
\end{itemize}

La matrice creuse correspondante peut être visualisée comme:
\[
    \begin{bmatrix}
        1 & 0 & 2 & 0 \\
        0 & 0 & 3 & 0 \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 4 \\
    \end{bmatrix}
\]

Le vecteur dense est simplementq:
\[
    \begin{bmatrix}
        1 \\
        2 \\
        3 \\
        4 \\
    \end{bmatrix}
\]

La multiplication de la matrice creuse par le vecteur dense est effectuée ligne
par ligne. Le résultat peut être visualisé comme :

\[
    \begin{bmatrix}
        1 & 0 & 2 & 0 \\
        0 & 0 & 3 & 0 \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 4 \\
    \end{bmatrix}
    \times
    \begin{bmatrix}
        1 \\
        2 \\
        3 \\
        4 \\
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 \times 1 + 0 \times 2 + 2 \times 3 + 0 \times 4 \\
        0 \times 1 + 0 \times 2 + 3 \times 3 + 0 \times 4 \\
        0 \times 1 + 0 \times 2 + 0 \times 3 + 0 \times 4 \\
        0 \times 1 + 0 \times 2 + 0 \times 3 + 4 \times 4 \\
    \end{bmatrix}
    =
    \begin{bmatrix}
        7  \\
        9  \\
        0  \\
        16 \\
    \end{bmatrix}
\]

\newpage
\section{Line-Based Parallelism}
This algorithm partitions a sparse matrix into row chunks and distributes these
chunks across multiple processes for parallel computation in a line-based
manner.

\begin{algorithm}[H]
    \caption{Line-based parallel sparse matrix-vector multiplication}
    \begin{algorithmic}
        \Require $M$ is an $m \times n$ sparse matrix
        \Require $v$ is an $n \times k$ vector
        \Require $numProcs$ is the number of processes
        \Require $rank$ is the rank of the current process
        \Ensure  $Result$ is a part of the $m \times k$ matrix computed by this process

        \State $rowsPerProc \gets m / numProcs$
        \State $startRow \gets rank \times rowsPerProc$
        \State $endRow \gets startRow + rowsPerProc$
        \State $Result \gets$ zero matrix of size $rowsPerProc \times k$

        \For{$i \gets startRow$ \textbf{to} $endRow-1$}
        \For{each non-zero element $(j, \text{value})$ in row $i$ of $M$}
        \For{$l \gets 0$ \textbf{to} $k-1$}
        \State $Result[i - startRow][l] \gets Result[i - startRow][l] + (\text{value} \times v[j][l])$
        \EndFor
        \EndFor
        \EndFor

        \If{$rank \neq 0$}
        \State Send $Result$ to process $0$
        \Else
        \State $FinalResult \gets$ zero matrix of size $m \times k$
        \State Copy $Result$ into $FinalResult$
        \For{$p \gets 1$ \textbf{to} $numProcs-1$}
        \State Receive partial $Result$ from process $p$
        \State Copy received $Result$ into appropriate position in $FinalResult$
        \EndFor
        \EndIf

        \State \textbf{if} $rank = 0$ \textbf{then} \Return $FinalResult$
    \end{algorithmic}
\end{algorithm}

\subsection{Complexity Analysis}
\subsubsection{Temporal Complexity}
\begin{itemize}
    \item \textbf{MPI Initialisation and Rank and Size Determination:} This step is generally fast, with a complexity close to \( O(1) \), as it mainly involves setup operations.
    \item \textbf{Calculation of the Number of Rows per Process:} This operation also has a complexity of \( O(1) \) as it requires only simple arithmetic based on the total size of the matrix and the number of processes.
    \item \textbf{Calculation of Start and End Indices for Each Process:} Again, this step has a complexity of \( O(1) \) as it involves simple arithmetic calculations.
    \item \textbf{Scatter of Rows of \( M \) and Vector \( v \):} The complexity of this step depends on the MPI implementation and data distribution. In general, it can be considered as \( O(\frac{n_{nz}}{p}) \), where \( n_{nz} \) is the total number of non-zero elements in the matrix and \( p \) is the number of processes.
    \item \textbf{Local Computation in Each Process:} Each process performs the matrix-vector product computation for its assigned portion of the matrix. The complexity of this step is \( O(\frac{n_{nz}}{p}) \) in the ideal case where the non-zero elements are evenly distributed among the processes.
    \item \textbf{Gather of Local Results \( r_{local} \):} The gather operation can vary in complexity, but generally, it is proportional to the total number of elements to be gathered and depends on the efficiency of communication between processes.
\end{itemize}

\subsubsection{Spatial Complexity}

\begin{itemize}
    \item \textbf{Storage of Sparse Matrix and Dense Vector:} The storage of the matrix and vector remains \( O(n_{nz} + m + n) \), where \( m \) and \( n \) are the dimensions of the matrix.
    \item \textbf{Local Result Vectors \( r_{local} \):} Each process stores a local result vector of a size proportional to the portion of the matrix it processes, approximately \( O(\frac{m}{p}) \).
\end{itemize}

\newpage
\section{Column-Wise Parallelism}
This algorithm distributes the non-zero elements of a sparse matrix among
different processes, enabling parallel computation focused on each non-zero
element.

\begin{algorithm}
    \caption{Column-wise Parallelization using MPI for Sparse Matrix-Fat Vector Multiplication}
    \begin{algorithmic}
        \Require $M$ is an $m \times n$ sparse matrix
        \Require $v$ is an $n \times k$ vector
        \Require $numProcs$ is the number of processes
        \Require $rank$ is the rank of the current process
        \Ensure  $PartialResult$ is a part of the $m \times k$ matrix computed by this process

        \State $colsPerProc \gets k / numProcs$
        \State $startCol \gets rank \times colsPerProc$
        \State $endCol \gets startCol + colsPerProc$
        \State $PartialResult \gets$ zero matrix of size $m \times colsPerProc$

        \For{$i \gets 0$ \textbf{to} $m-1$}
        \For{each non-zero element $(j, \text{value})$ in row $i$ of $M$}
        \For{$l \gets startCol$ \textbf{to} $endCol-1$}
        \State $PartialResult[i][l - startCol] \gets PartialResult[i][l - startCol] + (\text{value} \times v[j][l])$
        \EndFor
        \EndFor
        \EndFor

        \If{$rank \neq 0$}
        \State Send $PartialResult$ to process $0$
        \Else
        \State $FinalResult \gets$ zero matrix of size $m \times k$
        \State Copy $PartialResult$ into appropriate position in $FinalResult$
        \For{$p \gets 1$ \textbf{to} $numProcs-1$}
        \State Receive partial $PartialResult$ from process $p$
        \State Copy received $PartialResult$ into appropriate position in $FinalResult$
        \EndFor
        \EndIf

        \State \textbf{if} $rank = 0$ \textbf{then} \Return $FinalResult$
    \end{algorithmic}
\end{algorithm}

\subsection{Complexity Analysis}
\subsubsection{Temporal Complexity}
\begin{itemize}
    \item \textbf{MPI Initialisation and Rank and Size Determination:} Similar to the line-based approach, this step has a complexity of approximately \( O(1) \), involving basic setup operations.

    \item \textbf{Distribution of Non-Zero Elements of \( M \):} This step involves distributing the non-zero elements among the processes. The complexity depends on the distribution mechanism but is generally proportional to the number of non-zero elements, \( n_{nz} \), and the efficiency of the distribution algorithm used.

    \item \textbf{Scatter of Vector \( v \) to All Processes:} Scattering the vector \( v \) to all processes can be done efficiently in MPI and typically has a complexity proportional to the size of the vector, \( O(n) \).

    \item \textbf{Computation of Products for Assigned Non-Zero Elements:} Each process computes the products for its assigned non-zero elements. Assuming an even distribution, the complexity for each process would be \( O(\frac{n_{nz}}{p}) \), where \( p \) is the number of processes.

    \item \textbf{MPI Atomic Operations and Reduction:} The use of atomic operations and reduction to form the final result vector can introduce additional complexity, depending on the implementation and efficiency of these operations in MPI.
\end{itemize}

\subsubsection{Spatial Complexity}

\begin{itemize}
    \item \textbf{Storage of Sparse Matrix and Dense Vector:} The storage requirements remain the same as in the line-based approach, \( O(n_{nz} + m + n) \).

    \item \textbf{Local Result Vectors \( r_{local} \):} Each process maintains a local result vector, but since the computation is based on non-zero elements, the storage requirement for each \( r_{local} \) might be smaller, depending on the distribution of non-zero elements.
\end{itemize}

\newpage
\section{Non-Zero Element Parallelism}
This algorithm combines line-based and non-zero element-based approaches by
distributing chunks of rows to each process and then performing parallel
computations on the non-zero elements within those chunks.

\begin{algorithm}
    \caption{Non-Zero Element Parallelization using MPI for Sparse Matrix-Fat Vector Multiplication}
    \begin{algorithmic}
        \Require $M$ is an $m \times n$ sparse matrix stored in a format that allows iterating over non-zero elements (e.g., COO, CSR)
        \Require $v$ is an $n \times k$ vector
        \Require $numProcs$ is the number of processes
        \Require $rank$ is the rank of the current process
        \Ensure  $PartialResult$ is a part of the $m \times k$ matrix computed by this process

        \State $numNonZeroElements \gets$ total number of non-zero elements in $M$
        \State $elementsPerProc \gets numNonZeroElements / numProcs$
        \State $startIndex \gets rank \times elementsPerProc$
        \State $endIndex \gets startIndex + elementsPerProc$
        \State $PartialResult \gets$ zero matrix of size $m \times k$

        \State $NonZeroElements \gets$ list of non-zero elements in $M$ from $startIndex$ to $endIndex - 1$
        \For{each $(i, j, \text{value})$ in $NonZeroElements$}
            \For{$l \gets 0$ \textbf{to} $k-1$}
                \State $PartialResult[i][l] \gets PartialResult[i][l] + (\text{value} \times v[j][l])$
            \EndFor
        \EndFor

        \If{$rank \neq 0$}
            \State Send $PartialResult$ to process $0$
        \Else
            \State $FinalResult \gets$ zero matrix of size $m \times k$
            \State Copy $PartialResult$ into $FinalResult$
            \For{$p \gets 1$ \textbf{to} $numProcs-1$}
                \State Receive partial $PartialResult$ from process $p$
                \State Add received $PartialResult$ into $FinalResult$
            \EndFor
        \EndIf

        \State \textbf{if} $rank = 0$ \textbf{then} \Return $FinalResult$
    \end{algorithmic}
\end{algorithm}


\subsection{Complexity Analysis}
\subsubsection{Temporal Complexity}

\begin{itemize}
    \item \textbf{MPI Initialisation and Rank and Size Determination:} As with other MPI-based algorithms, this step has a complexity of approximately \( O(1) \).

    \item \textbf{Scattering Chunks of Rows of \( M \) to Each Process:} This step distributes parts of the matrix to different processes. Its complexity depends on the number of rows and the distribution method, typically around \( O(\frac{m}{p}) \), where \( m \) is the number of rows and \( p \) is the number of processes.

    \item \textbf{Scatter of Vector \( v \) to All Processes:} This operation generally has a complexity of \( O(n) \), where \( n \) is the size of the vector.

    \item \textbf{Local Computations for Non-Zero Elements:} Each process computes the products for the non-zero elements in its assigned rows. Assuming an even distribution of non-zero elements, the complexity for each process is approximately \( O(\frac{n_{nz}}{p}) \).

    \item \textbf{Gather of Local Results \( r_{local} \) into Final Result Vector \( r \):} This step combines the partial results from all processes and typically has a complexity proportional to the total number of elements in \( r \).
\end{itemize}

\subsubsection{Spatial Complexity}

\begin{itemize}
    \item \textbf{Storage of Sparse Matrix and Dense Vector:} The overall storage requirements remain \( O(n_{nz} + m + n) \), as in other sparse matrix-vector multiplication methods.

    \item \textbf{Local Result Vectors \( r_{local} \):} Each process stores a local result vector for its chunk of rows, with the size depending on the distribution of rows and non-zero elements.
\end{itemize}

\subsection*{Complexity and Considerations}

Each of these parallel algorithms aims to exploit different aspects of
parallelism, with the primary goal of reducing the overall computation time.
The actual performance gain depends on the characteristics of the sparse
matrix, the number of available processing units, and the specific
implementation details. Moreover, care must be taken to manage concurrency
issues, such as race conditions and proper synchronization, to ensure correct
and efficient execution.

\newpage
\chapter{Conclusion}

\bibliographystyle{CranfieldNumbered}
\bibliography{CUCitations}

\appendix
\chapter{Documentation}

\begin{subappendices}
    \section{Project tree}
    \begin{lstlisting}[breaklines=true, basicstyle=\small]
    lib/
        collecting.py
        processing.py
        storing.py
    scripts/
        get_iam_credentials.sh
        start_spark_job.sh
    services/
        get_iam_credentials.service
        spark_python_job.service
    test/
        artillery_load_test.yml
        monitoring.py
        metrics.csv
        results.json
        visualisation_load_test.ipynb
    main.py
    README.md
    requirements.txt
    \end{lstlisting}

    \section{Getting Started}
    To run the program, follow these steps:
    \begin{enumerate}
        \itemindent=17.87pt
        \item Create a virtual environment using \texttt{python3 -m venv venv}.
        \item Activate the virtual environment using \texttt{source venv/bin/activate}.
        \item Install the required dependencies using \texttt{pip3 install -r
                  requirements.txt}.
        \item Run the program using \texttt{python3 main.py}.
        \item Visualise the results using \texttt{visualisation.ipynb} (Jupyter Notebook).
    \end{enumerate}

    \section{Detailed Features of Functions}
    \begin{description}
        \item \texttt{collecting.py}
              \begin{itemize}
                  \item \texttt{fetch\_sensors\_data(sparkSession)}: Function to ingest the latest data from the sensors and returns it as a Spark DataFrame.
              \end{itemize}

        \item \texttt{processing.py}
              \begin{itemize}
                  \item \texttt{get\_aqi\_value\_p25(value)}: Function for calculating the AQI value for PM2.5.
                  \item \texttt{get\_aqi\_value\_p10(value)}: Function for calculating the AQI value for PM10.
                  \item \texttt{computeAQI(df)}: Function for calculating the AQI value for each particulate matter sensor and returning the DataFrame with the AQI column.
              \end{itemize}

        \item \texttt{storing.py}
              \begin{itemize}
                  \item \texttt{keepOnlyUpdatedRows(database\_name, table\_name, df)}: Function for keeping only the rows that have been updated in the DataFrame.
                  \item \texttt{\_print\_rejected\_records\_exceptions(err)}: Internal function for printing the rejected records exceptions.
                  \item \texttt{write\_records(database\_name, table\_name, client, records)}: Internal function for writing a batch of records to the Timestream database.
                  \item \texttt{writeToTimestream(database\_name, table\_name, partionned\_df)}: Function for writing the DataFrame to the Timestream database.
              \end{itemize}
    \end{description}
\end{subappendices}

\chapter{Source Codes}
\begin{subappendices}
    \section{Data Structures}\label{appendix:data-structures}
    Data stuctures of the sparse matrix and dense vector.
    \lstinputlisting[style=cstyle]{../Source Code/MatrixDefinitions.h}
    
    \newpage

    \section{Sequential Algorithm}\label{appendix:sequential}
    Sequential algorithm for multiplying a sparse matrix by a dense vector.
    \subsection{Declaration File}
    \lstinputlisting[style=cstyle]{../Source Code/SparseMatrixDenseVectorMultiply.h}
    \subsection{Implementation File}
    \lstinputlisting[style=cstyle]{../Source Code/SparseMatrixDenseVectorMultiply.cpp}

    \section{Line-Based Parallelism}\label{appendix:line-based}
    Parallel algorithm for multiplying a sparse matrix by a dense vector using line-based parallelism.
    \subsection{Declaration File}
    \lstinputlisting[style=cstyle]{../Source Code/SparseMatrixDenseVectorMultiplyRowWise.h}
    \subsection{Implementation File}
    \lstinputlisting[style=cstyle]{../Source Code/SparseMatrixDenseVectorMultiplyRowWise.cpp}

    \section{Column-Wise Parallelism}\label{appendix:column-based}
    Parallel algorithm for multiplying a sparse matrix by a dense vector using column-wise parallelism.
    \subsection{Declaration File}
    \lstinputlisting[style=cstyle]{../Source Code/SparseMatrixDenseVectorMultiplyColumnWise.h}
    \subsection{Implementation File}
    \lstinputlisting[style=cstyle]{../Source Code/SparseMatrixDenseVectorMultiplyColumnWise.cpp}

    \section{Non-Zero Element Parallelism}\label{appendix:non-zero}
    Parallel algorithm for multiplying a sparse matrix by a dense vector using non-zero element parallelism.
    \subsection{Declaration File}
    \lstinputlisting[style=cstyle]{../Source Code/SparseMatrixDenseVectorMultiplyNonZeroElement.h}
    \subsection{Implementation File}
    \lstinputlisting[style=cstyle]{../Source Code/SparseMatrixDenseVectorMultiplyNonZeroElement.cpp}

    \section{Utility Functions}\label{appendix:utility}
    Utility functions used by the main file.
    \subsection{Declaration File}
    \lstinputlisting[style=cstyle]{../Source Code/utils.h}
    \subsection{Implementation File}
    \lstinputlisting[style=cstyle]{../Source Code/utils.cpp}

    \section{Main File}\label{appendix:main}
    Main file for running the different algorithms and comparing their performance.
    \lstinputlisting[style=cstyle]{../Source Code/main.cpp}

    \section{Scripts}\label{appendix:scripts}
    \subsection{MPI Submission Script}
    Bash script to submit an MPI job to the cluster.
    \lstinputlisting[style=bashstyle]{../Source Code/scripts/mpi.sub}

    \newpage
    \subsection{Batch Test Script}
    Bash script to submit multiple MPI jobs to the cluster.
    \lstinputlisting[style=bashstyle]{../Source Code/scripts/batch_test.sh}

    \newpage
    \subsection{Get CSV Script}
    Bash script to analyse all job results files and extract the relevant information to create a CSV file.
    \lstinputlisting[style=bashstyle]{../Source Code/scripts/get_csv_all.sh}
    

\end{subappendices}

\end{document}

